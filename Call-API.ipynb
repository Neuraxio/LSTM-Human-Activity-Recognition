{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "from neuraxle.base import NonFittableMixin\n",
    "\n",
    "from data_reading import DATASET_PATH, TRAIN, TEST, X_train_signals_paths, X_test_signals_paths, load_X, load_y, \\\n",
    "    TRAIN_FILE_NAME, TEST_FILE_NAME\n",
    "from neuraxle.api.flask import FlaskRestApiWrapper\n",
    "from neuraxle.base import ExecutionContext, DEFAULT_CACHE_FOLDER, ExecutionMode, BaseStep\n",
    "from neuraxle.hyperparams.space import HyperparameterSamples\n",
    "from savers.tensorflow1_step_saver import TensorflowV1StepSaver\n",
    "from neuraxle.steps.encoding import OneHotEncoder\n",
    "\n",
    "from pipeline import HumanActivityRecognitionPipeline, BATCH_SIZE\n",
    "from steps.custom_json_decoder_for_2darray import CustomJSONDecoderFor2DArray\n",
    "from steps.custom_json_encoder_of_outputs import CustomJSONEncoderOfOutputs\n",
    "from neuraxle.pipeline import MiniBatchSequentialPipeline, Joiner\n",
    "from neuraxle.steps.output_handlers import OutputTransformerWrapper\n",
    "\n",
    "# TODO: move in a package neuraxle-tensorflow \n",
    "from savers.tensorflow1_step_saver import TensorflowV1StepSaver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some useful info to get an insight on dataset's shape and normalisation:\n",
      "(X shape, y shape, every X's mean, every X's standard deviation)\n",
      "(2947, 128, 9) (2947, 1) 0.09913992 0.39567086\n",
      "The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\n"
     ]
    }
   ],
   "source": [
    "from data_reading import DATASET_PATH, TRAIN, TEST, X_train_signals_paths, X_test_signals_paths, load_X, load_y, \\\n",
    "    TRAIN_FILE_NAME, TEST_FILE_NAME\n",
    "\n",
    "DATA_PATH = \"data/\"\n",
    "DATASET_PATH = DATA_PATH + \"UCI HAR Dataset/\"\n",
    "\n",
    "# Load \"X\" (the neural network's training and testing inputs)\n",
    "\n",
    "# X_train = load_X(X_train_signals_paths)\n",
    "X_test = load_X(X_test_signals_paths)\n",
    "\n",
    "# Load \"y\" (the neural network's training and testing outputs)\n",
    "\n",
    "# y_train_path = os.path.join(DATASET_PATH, TRAIN, TRAIN_FILE_NAME)\n",
    "y_test_path = os.path.join(DATASET_PATH, TEST, TEST_FILE_NAME)\n",
    "\n",
    "# y_train = load_y(y_train_path)\n",
    "y_test = load_y(y_test_path)\n",
    "\n",
    "print(\"Some useful info to get an insight on dataset's shape and normalisation:\")\n",
    "print(\"(X shape, y shape, every X's mean, every X's standard deviation)\")\n",
    "print(X_test.shape, y_test.shape, np.mean(X_test), np.std(X_test))\n",
    "print(\"The dataset is therefore properly normalised, as expected, but not yet one-hot encoded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class APICaller(NonFittableMixin, BaseStep):\n",
    "    def transform(self, data_inputs):\n",
    "        req = urllib.request.Request(\n",
    "            'http://127.0.0.1:5000/',\n",
    "            method=\"GET\",\n",
    "            headers={'content-type': 'application/json'},\n",
    "            data=json.dumps(data_inputs.tolist()).encode('utf8')\n",
    "        )\n",
    "        response = urllib.request.urlopen(req)\n",
    "        test_predictions = json.loads(response.read())\n",
    "        return test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline(\n",
    "    json_encoder=CustomJSONEncoderOfOutputs(),\n",
    "    wrapped=APICaller(url=\"http://localhost:5000/\"),\n",
    "    json_decoder=CustomJSONDecoderFor2DArray()\n",
    ")\n",
    "y_pred = p.predict(X_test)\n",
    "\n",
    "# TODO: \n",
    "# y_test = y_test.argmax(1) ???? is this already made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Inline plots: )\n",
    "%matplotlib inline\n",
    "\n",
    "font = {\n",
    "    'family' : 'Bitstream Vera Sans',\n",
    "    'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "# Results\n",
    "\n",
    "predictions = y_pred.argmax(1)\n",
    "\n",
    "print(\"Testing Accuracy: {}%\".format(100*accuracy))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Precision: {}%\".format(100*metrics.precision_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"Recall: {}%\".format(100*metrics.recall_score(y_test, predictions, average=\"weighted\")))\n",
    "print(\"f1_score: {}%\".format(100*metrics.f1_score(y_test, predictions, average=\"weighted\")))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, predictions)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)\n",
    "print(\"Note: training and testing data is not equally distributed amongst classes, \")\n",
    "print(\"so it is normal that more than a 6th of the data is correctly classifier in the last category.\")\n",
    "\n",
    "# Plot Results:\n",
    "width = 12\n",
    "height = 12\n",
    "plt.figure(figsize=(width, height))\n",
    "plt.imshow(\n",
    "    normalised_confusion_matrix,\n",
    "    interpolation='nearest',\n",
    "    cmap=plt.cm.rainbow\n",
    ")\n",
    "plt.title(\"Confusion matrix \\n(normalised to % of total test data)\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(n_classes)\n",
    "plt.xticks(tick_marks, LABELS, rotation=90)\n",
    "plt.yticks(tick_marks, LABELS)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.teardown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Human Activity Recognition",
   "language": "python",
   "name": "human-activity-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
